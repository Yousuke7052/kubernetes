# 使用kubeadm部署集群
### 1.環境準備
##### [~]# lsb_release -a
##### No LSB modules are available.
##### Distributor ID: Ubuntu
##### Description:    Ubuntu 20.04.6 LTS
##### Release:        20.04
##### Codename:       focal
##### [~]# sudo apt update
##### 靜態IP設定
##### master 2c2g 192.168.205.200
##### node1 2c2g 192.168.205.201
##### node2 2c2g 192.168.205.202
####### [~]# sudo apt install vim
####### [~]# sudo apt install net-tools
####### [~]# sudo cp /etc/netplan/01-network-manager-all.yaml 01-network-manager-all.yaml.bak
####### [~]# vim cp /etc/netplan/01-network-manager-all.yaml         # 改ip用
####### 改成下面這樣,縮進不能有閃失
####### #>>>>>>>
####### network:
#######   version: 2
#######   renderer: NetworkManager
#######   ethernets:
#######     ens33:
#######       dhcp4: no
#######       addresses:
#######         - 192.168.205.200/24
#######       gateway4: 192.168.205.2
#######       nameservers:
#######         addresses: [8.8.8.8, 8.8.4.4]
####### #<<<<<<<
####### [~]# sudo netplan apply
####### 三台可同步操作
####### [~]# sudo apt install vim
####### [~]# sudo apt install net-tools

### 2.集群安裝環境準備
##### 1)各節點主機名解析
####### 三台可同步操作
####### [~]# sudo nano /etc/hosts
####### 192.168.205.200 master                                        # 三台主機皆輸入這三行內容至文件中
####### 192.168.205.201 node1                                         # 三台主機皆輸入這三行內容至文件中
####### 192.168.205.202 node2                                         # 三台主機皆輸入這三行內容至文件中
####### 文件上方改為
####### 127.0.1.1   <new-hostname>
####### [~]# sudo nano /etc/hosts
####### new-hostname
####### [~]# sudo reboot                                              # 改完後重啟   
#######
#######
##### 2)關閉防火牆、關閉seLinux
####### 三台可同步操作
####### # 停用和禁用 ufw（防火牆）
####### [~]# sudo ufw disable
####### # 停用和禁用 apparmor（安全框架）
####### [~]# sudo systemctl stop apparmor
####### [~]# sudo systemctl disable apparmor
####### # 確認 ufw 和 apparmor 的狀態
####### [~]# sudo ufw status
####### [~]# sudo aa-status
#######
#######
##### 3)關閉交換分區
####### 做k8s,不需要用交換分區,交換分區:物理內存不夠時會使用,用了會導致運行速度很慢,因為交換分區是在硬盤讀寫速度慢於內存
####### 三台可同步操作
####### # 禁用 SWAP
####### [~]# sudo swapoff -a
####### [~]# sudo sed -i '/ swap / s/^/#/' /etc/fstab
####### [~]# free -have                                               # Swap那一行會顯示為0 有total,used,free
#######
#######
##### 4)各節點主機時間同步
####### 分開操作
####### master機台操作:
####### [~]# sudo apt update
####### [~]# sudo apt install chrony
####### [~]# vim /etc/chrony/chrony.conf
####### server 0.ubuntu.pool.ntp.org iburst
####### server 1.ubuntu.pool.ntp.org iburst
####### server 2.ubuntu.pool.ntp.org iburst
####### server 3.ubuntu.pool.ntp.org iburst
####### #Allow NTP client access from local network.
####### #allow 192.168.0.0/16
####### 這行新增自己設定的網段,就是205
####### allow 192.168.205.0/24
####### [~]# netstat -tunlp                                            # 時間同步服務佔用123,323兩個端口,
#######                                                                # 默認開啟323,客戶端用的,123服務端用
####### [~]# systemctl restart chronyd
####### [~]# netstat -tunlp
####### node機台操作:
####### [~]# vim /etc/chrony.conf
####### #server 0.ubuntu.pool.ntp.org iburst
####### #server 1.ubuntu.pool.ntp.org iburst
####### #server 2.ubuntu.pool.ntp.org iburst
####### #server 3.ubuntu.pool.ntp.org iburst
####### server 192.168.205.200 iburst
####### [~]# systemctl restart chronyd
####### [~]# chronyc sources -v                                         # Name/IP address下應該為^* master
#######                                                                 # 若*是?就有問題了 問號表示沒連接上master時間
#######
#######
##### 5)配置網路模塊與參數
####### 查看模塊是否加載
####### [~]# lsmod | grep overlay                                       # 若沒加載會沒訊息
####### [~]# lsmod | grep br_netfilter                                  # 若沒加載會沒訊息
####### [~]# modprobe -a overlay
####### [~]# modprobe -a br_netfilter
####### [~]# lsmod | grep overlay                                       
####### [~]# lsmod | grep br_netfilter                                  
####### [~]# cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
#######      overlay
#######      br_netfilter
#######      ip_vs
#######      ip_vs_wrr
#######      ip_vs_sh
#######      ip_vs_rr
#######      EOF
####### 修改網橋網路參數:解決於iptables被繞過而導致流量路由不正確問題
####### [~]# cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
#######      net.ipv4.ip_forward = 1
#######      vm.swappiness = 0
#######      net.bridge.bridge-nf-call-ip6tables = 1
#######      net.bridge.bridge-nf-call-iptables = 1
#######      EOF
####### [~]# sudo sysctl --system
####### 檢查內核參數,以下四行結果分別為1, 0, 1, 1
####### [~]# sysctl net.ipv4.ip_forward
####### [~]# sysctl vm.swappiness
####### [~]# sysctl net.bridge.bridge-nf-call-ip6tables
####### [~]# sysctl net.bridge.bridge-nf-call-iptables
#######
#######
##### 6)安裝容器
####### 安裝container
####### [~]# sudo apt install -y containerd
####### 配置container
####### [~]# sudo mkdir -p /etc/containerd
####### [~]# containerd config default | sudo tee /etc/containerd/config.toml
####### 重啟container
####### [~]# sudo systemctl restart containerd
####### 檢查container
####### [~]# sudo systemctl status containerd
####### [~]# ctr version
#######
#######
##### 7) kubeadm、kubelet、kubectl組件的安裝
####### 安裝必要的依賴:
####### [~]# sudo apt install -y curl apt-transport-https ca-certificates gnupg
####### 可能安裝失敗,刪除現有的APT,若想嘗試其他源,執行下面這一行
####### [~]# sudo rm /etc/apt/sources.list.d/kubernetes.list
####### 不確定可以先查看看存放gpg密鑰的資料夾存不存在, 不存在要創建
####### [~]# sudo mkdir -p /etc/apt/keyrings
####### [~]# curl -fsSL https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes.gpg
####### 這裡是鏡像源:
####### [~]# echo "deb [signed-by=/etc/apt/keyrings/kubernetes.gpg] https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
####### [~]# sudo apt update
####### 列出可用版本
####### [~]# sudo apt-cache policy kubelet kubeadm kubectl
####### [~]# sudo apt install -y kubelet=1.26.3-00 kubeadm=1.26.3-00 kubectl=1.26.3-00
####### 鎖定版本防止意外升級
####### [~]# sudo apt-mark hold kubelet kubeadm kubectl
####### 檢查版本
####### [~]# kubelet --version
####### [~]# kubeadm version
####### [~]# kubectl version --client
#######
#######
##### 8)初始化集群
####### master機台操作:
####### [~]# sudo kubeadm init --pod-network-cidr=10.244.0.0/16
####### 配置kubelet
####### [~]# mkdir -p $HOME/.kube
####### [~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
####### [~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config
####### 安裝pod網路插件
####### [~]# kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
####### 驗證pod網路插件
####### [~]# kubectl get pods --all-namespaces
####### 驗證master節點狀態
####### [~]# kubectl get nodes
####### 檢查並拉取必要鏡像
####### [~]# sudo kubeadm config images pull --image-repository=registry.aliyuncs.com/google_containers
####### 
####### 這邊是三節點要做的
####### 创建 crictl 配置文件
####### [~]# cat <<EOF | sudo tee /etc/crictl.yaml
#######      runtime-endpoint: unix:///run/containerd/containerd.sock
#######      image-endpoint: unix:///run/containerd/containerd.sock
#######      timeout: 10
#######      debug: false
#######      EOF
####### 修改cgroups
####### [~]# sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
####### 確保CRI插件未禁用
####### [~]# sudo sed -i '/disabled_plugins =/d' /etc/containerd/config.toml
####### 修改sandbox_image的值
####### [~]# sudo kubeadm config images list --image-repository=registry.aliyuncs.com/google_containers
####### [~]# sudo sed -i 's/sandbox_image = .*/sandbox_image = "registry.aliyuncs.com\/google_containers\/pause:3.9"/' /etc/containerd/config.toml
####### 重啟container
####### [~]# sudo systemctl restart containerd
####### 檢查拉取的鏡像
####### [~]# sudo crictl images
####### 若NODE節點拉取鏡像錯誤，可以執行以下命令
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/kube-apiserver:v1.26.15 || sudo crictl pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.26.15
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/kube-controller-manager:v1.26.15 || sudo crictl pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.26.15
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/kube-scheduler:v1.26.15 || sudo crictl pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.26.15
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/kube-proxy:v1.26.15 || sudo crictl pull registry.aliyuncs.com/google_containers/kube-proxy:v1.26.15
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/pause:3.9 || sudo crictl pull registry.aliyuncs.com/google_containers/pause:3.9
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/etcd:3.5.6-0 || sudo crictl pull registry.aliyuncs.com/google_containers/etcd:3.5.6-0
####### [~]# sudo crictl images | grep registry.aliyuncs.com/google_containers/coredns:v1.9.3 || sudo crictl pull registry.aliyuncs.com/google_containers/coredns:v1.9.3
#######
#######
##### 9)加入集群
#######首先,master運行這一行
####### [~]# kubeadm token create --print-join-command
####### 會生成類似以下的命令
####### kubeadm join <master-ip>:<master-port> --token <token> --discovery-token-ca-cert-hash sha256:<hash>
####### 然後改成以下這樣去node節點上運行
####### [~]# sudo kubeadm join <master-ip>:<master-port> --token <token> --discovery-token-ca-cert-hash sha256:<hash>
####### 加入失敗時:
####### [~]# sudo kubeadm reset     # 按y
####### [~]# sudo systemctl restart kubelet
####### 再次重新加入
####### [~]# sudo kubeadm join <master-ip>:<master-port> --token <token> --discovery-token-ca-cert-hash sha256:<hash>
####### master上運行,以查看節點狀況
####### [~]# kubectl get nodes
